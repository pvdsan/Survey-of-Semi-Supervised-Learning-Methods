{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./Mnist_10000._samples.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the structured array to PyTorch tensors\n",
    "images = torch.tensor([item['image'] for item in data], dtype=torch.float32)\n",
    "labels = torch.tensor([item['label'] for item in data], dtype=torch.long)\n",
    "\n",
    "# Flatten the images for a simple fully connected network\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = TensorDataset(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {k: [] for k in range(10)}  # Assuming 10 classes (0-9)\n",
    "for idx, (image, label) in enumerate(dataset):\n",
    "    class_indices[label.item()].append(idx)\n",
    "\n",
    "# Step 2: Randomly select 10 samples from each class\n",
    "labeled_indices = []\n",
    "for indices in class_indices.values():\n",
    "    labeled_indices.extend(np.random.choice(indices, 10, replace=False))\n",
    "\n",
    "# Create a mask for the rest of the data for testing\n",
    "mask = np.ones(len(dataset), dtype=bool)\n",
    "mask[labeled_indices] = False\n",
    "unlabeled_indices = np.arange(len(dataset))[mask]\n",
    "\n",
    "# Step 3: Create training and testing subsets\n",
    "labeled_set = Subset(dataset, labeled_indices)\n",
    "unlabeled_set = Subset(dataset, unlabeled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create DataLoaders\n",
    "labeledLoader = DataLoader(labeled_set, batch_size=10, shuffle=True)\n",
    "unlabeledLoader = DataLoader(unlabeled_set, batch_size=50, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        self.fullyConnectedLayer = nn.Sequential(\n",
    "            nn.Linear(784, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.fullyConnectedLayer(input)\n",
    "        activatedOutput = F.log_softmax(output, dim = 1)\n",
    "\n",
    "        return activatedOutput\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence_with_logits(p_logits, q_logits):\n",
    "    p = F.softmax(p_logits, dim=1)\n",
    "    log_p = F.log_softmax(p_logits, dim=1)\n",
    "    log_q = F.log_softmax(q_logits, dim=1)\n",
    "    kl = torch.sum(p * (log_p - log_q), dim=1)\n",
    "    return kl.mean()\n",
    "\n",
    "def virtual_adversarial_loss(model, x, epsilon=0.02):\n",
    "    x.requires_grad_()\n",
    "    with torch.enable_grad():\n",
    "        logits = model(x)\n",
    "        logits_perturbed = model(x + epsilon * torch.randn_like(x))\n",
    "        loss = kl_divergence_with_logits(logits, logits_perturbed)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Epoch0 SuperVised_Loss:2.212797164916992,       VAT_loss = 1.9250153854954988e-05,   Total_Loss:2.2128164768218994\n",
      "For Epoch0 VAT_LOSS_UNLABELED:1.7019729057210498e-05\n",
      "For Epoch1 SuperVised_Loss:2.191187620162964,       VAT_loss = 1.8329688828089274e-05,   Total_Loss:2.1912059783935547\n",
      "For Epoch1 VAT_LOSS_UNLABELED:1.70345556398388e-05\n",
      "For Epoch2 SuperVised_Loss:2.2240986824035645,       VAT_loss = 2.2615375200985e-05,   Total_Loss:2.224121332168579\n",
      "For Epoch2 VAT_LOSS_UNLABELED:1.8634174921317026e-05\n",
      "For Epoch3 SuperVised_Loss:2.0205984115600586,       VAT_loss = 3.0069513741182163e-05,   Total_Loss:2.0206284523010254\n",
      "For Epoch3 VAT_LOSS_UNLABELED:1.8652455764822662e-05\n",
      "For Epoch4 SuperVised_Loss:1.8592243194580078,       VAT_loss = 1.5717281712568365e-05,   Total_Loss:1.8592400550842285\n",
      "For Epoch4 VAT_LOSS_UNLABELED:2.0284278434701264e-05\n",
      "For Epoch5 SuperVised_Loss:2.235863208770752,       VAT_loss = 1.7860696971183643e-05,   Total_Loss:2.2358810901641846\n",
      "For Epoch5 VAT_LOSS_UNLABELED:1.6748208508943208e-05\n",
      "For Epoch6 SuperVised_Loss:2.022010326385498,       VAT_loss = 1.9518194676493295e-05,   Total_Loss:2.0220298767089844\n",
      "For Epoch6 VAT_LOSS_UNLABELED:2.2287973479251377e-05\n",
      "For Epoch7 SuperVised_Loss:2.1844594478607178,       VAT_loss = 1.894685556180775e-05,   Total_Loss:2.184478282928467\n",
      "For Epoch7 VAT_LOSS_UNLABELED:1.8834072761819698e-05\n",
      "For Epoch8 SuperVised_Loss:2.1511199474334717,       VAT_loss = 2.6581043130136095e-05,   Total_Loss:2.151146411895752\n",
      "For Epoch8 VAT_LOSS_UNLABELED:1.7976115486817434e-05\n",
      "For Epoch9 SuperVised_Loss:2.2181429862976074,       VAT_loss = 1.936598346219398e-05,   Total_Loss:2.2181622982025146\n",
      "For Epoch9 VAT_LOSS_UNLABELED:2.374699033680372e-05\n",
      "For Epoch10 SuperVised_Loss:2.1973516941070557,       VAT_loss = 1.5712055756011978e-05,   Total_Loss:2.1973674297332764\n",
      "For Epoch10 VAT_LOSS_UNLABELED:2.416099414404016e-05\n",
      "For Epoch11 SuperVised_Loss:2.0045838356018066,       VAT_loss = 1.833024543884676e-05,   Total_Loss:2.0046021938323975\n",
      "For Epoch11 VAT_LOSS_UNLABELED:2.278618012496736e-05\n",
      "For Epoch12 SuperVised_Loss:2.192735195159912,       VAT_loss = 1.5877554687904194e-05,   Total_Loss:2.192751169204712\n",
      "For Epoch12 VAT_LOSS_UNLABELED:2.4398295863647945e-05\n",
      "For Epoch13 SuperVised_Loss:2.2051215171813965,       VAT_loss = 1.867347782535944e-05,   Total_Loss:2.2051401138305664\n",
      "For Epoch13 VAT_LOSS_UNLABELED:2.102750113408547e-05\n",
      "For Epoch14 SuperVised_Loss:2.196786403656006,       VAT_loss = 1.848219835665077e-05,   Total_Loss:2.196805000305176\n",
      "For Epoch14 VAT_LOSS_UNLABELED:2.1338859369279817e-05\n",
      "For Epoch15 SuperVised_Loss:2.2022697925567627,       VAT_loss = 2.5274373911088333e-05,   Total_Loss:2.2022950649261475\n",
      "For Epoch15 VAT_LOSS_UNLABELED:2.2270223780651577e-05\n",
      "For Epoch16 SuperVised_Loss:2.2217113971710205,       VAT_loss = 2.164477700716816e-05,   Total_Loss:2.2217330932617188\n",
      "For Epoch16 VAT_LOSS_UNLABELED:2.2096492102718912e-05\n",
      "For Epoch17 SuperVised_Loss:1.967917799949646,       VAT_loss = 3.38159516104497e-05,   Total_Loss:1.9679516553878784\n",
      "For Epoch17 VAT_LOSS_UNLABELED:2.6410842110635713e-05\n",
      "For Epoch18 SuperVised_Loss:1.9815406799316406,       VAT_loss = 2.753476110228803e-05,   Total_Loss:1.9815682172775269\n",
      "For Epoch18 VAT_LOSS_UNLABELED:2.294392470503226e-05\n",
      "For Epoch19 SuperVised_Loss:2.154348373413086,       VAT_loss = 2.901348671002779e-05,   Total_Loss:2.1543774604797363\n",
      "For Epoch19 VAT_LOSS_UNLABELED:2.3611810320289806e-05\n",
      "For Epoch20 SuperVised_Loss:1.987243413925171,       VAT_loss = 2.844011214619968e-05,   Total_Loss:1.9872719049453735\n",
      "For Epoch20 VAT_LOSS_UNLABELED:2.4614690119051374e-05\n",
      "For Epoch21 SuperVised_Loss:2.007396936416626,       VAT_loss = 2.6040350348921493e-05,   Total_Loss:2.007422924041748\n",
      "For Epoch21 VAT_LOSS_UNLABELED:2.2861850084154867e-05\n",
      "For Epoch22 SuperVised_Loss:2.1325058937072754,       VAT_loss = 2.8353901143418625e-05,   Total_Loss:2.1325342655181885\n",
      "For Epoch22 VAT_LOSS_UNLABELED:2.374053292442113e-05\n",
      "For Epoch23 SuperVised_Loss:2.0052711963653564,       VAT_loss = 3.456897320575081e-05,   Total_Loss:2.005305767059326\n",
      "For Epoch23 VAT_LOSS_UNLABELED:2.7750984372687526e-05\n",
      "For Epoch24 SuperVised_Loss:2.2026405334472656,       VAT_loss = 2.0098083041375503e-05,   Total_Loss:2.20266056060791\n",
      "For Epoch24 VAT_LOSS_UNLABELED:2.6239473299938254e-05\n",
      "For Epoch25 SuperVised_Loss:1.9891726970672607,       VAT_loss = 2.282215609739069e-05,   Total_Loss:1.989195466041565\n",
      "For Epoch25 VAT_LOSS_UNLABELED:2.7657120881485753e-05\n",
      "For Epoch26 SuperVised_Loss:2.0491585731506348,       VAT_loss = 2.2575599359697662e-05,   Total_Loss:2.0491812229156494\n",
      "For Epoch26 VAT_LOSS_UNLABELED:3.1214047339744866e-05\n",
      "For Epoch27 SuperVised_Loss:1.8166335821151733,       VAT_loss = 2.282955938426312e-05,   Total_Loss:1.816656470298767\n",
      "For Epoch27 VAT_LOSS_UNLABELED:3.0264302040450275e-05\n",
      "For Epoch28 SuperVised_Loss:2.220579147338867,       VAT_loss = 3.0021072234376334e-05,   Total_Loss:2.220609188079834\n",
      "For Epoch28 VAT_LOSS_UNLABELED:3.069233935093507e-05\n",
      "For Epoch29 SuperVised_Loss:1.8048843145370483,       VAT_loss = 1.8859916963265277e-05,   Total_Loss:1.8049031496047974\n",
      "For Epoch29 VAT_LOSS_UNLABELED:2.9390230338322e-05\n",
      "For Epoch30 SuperVised_Loss:1.9322493076324463,       VAT_loss = 4.29266037826892e-05,   Total_Loss:1.9322922229766846\n",
      "For Epoch30 VAT_LOSS_UNLABELED:2.9734357667621225e-05\n",
      "For Epoch31 SuperVised_Loss:2.1969687938690186,       VAT_loss = 2.72755314654205e-05,   Total_Loss:2.196995973587036\n",
      "For Epoch31 VAT_LOSS_UNLABELED:3.071287937927991e-05\n",
      "For Epoch32 SuperVised_Loss:1.7711254358291626,       VAT_loss = 3.083884803345427e-05,   Total_Loss:1.7711563110351562\n",
      "For Epoch32 VAT_LOSS_UNLABELED:2.768630838545505e-05\n",
      "For Epoch33 SuperVised_Loss:2.0054421424865723,       VAT_loss = 3.7084428186062723e-05,   Total_Loss:2.005479335784912\n",
      "For Epoch33 VAT_LOSS_UNLABELED:2.797296292555984e-05\n",
      "For Epoch34 SuperVised_Loss:2.185250759124756,       VAT_loss = 3.11462463287171e-05,   Total_Loss:2.185281991958618\n",
      "For Epoch34 VAT_LOSS_UNLABELED:3.095651845796965e-05\n",
      "For Epoch35 SuperVised_Loss:1.5898395776748657,       VAT_loss = 3.906926212948747e-05,   Total_Loss:1.5898786783218384\n",
      "For Epoch35 VAT_LOSS_UNLABELED:3.3896569220814854e-05\n",
      "For Epoch36 SuperVised_Loss:1.9286943674087524,       VAT_loss = 3.017168455698993e-05,   Total_Loss:1.9287245273590088\n",
      "For Epoch36 VAT_LOSS_UNLABELED:3.0237646569730714e-05\n",
      "For Epoch37 SuperVised_Loss:1.9205290079116821,       VAT_loss = 3.0280691134976223e-05,   Total_Loss:1.920559287071228\n",
      "For Epoch37 VAT_LOSS_UNLABELED:3.220212965970859e-05\n",
      "For Epoch38 SuperVised_Loss:1.9970695972442627,       VAT_loss = 2.036034311458934e-05,   Total_Loss:1.9970899820327759\n",
      "For Epoch38 VAT_LOSS_UNLABELED:3.493643816909753e-05\n",
      "For Epoch39 SuperVised_Loss:2.1481566429138184,       VAT_loss = 2.4170969481929205e-05,   Total_Loss:2.1481807231903076\n",
      "For Epoch39 VAT_LOSS_UNLABELED:3.343980642966926e-05\n",
      "For Epoch40 SuperVised_Loss:2.145317554473877,       VAT_loss = 2.9112512493156828e-05,   Total_Loss:2.1453466415405273\n",
      "For Epoch40 VAT_LOSS_UNLABELED:3.460449806880206e-05\n",
      "For Epoch41 SuperVised_Loss:1.9841556549072266,       VAT_loss = 2.9780814656987786e-05,   Total_Loss:1.9841854572296143\n",
      "For Epoch41 VAT_LOSS_UNLABELED:3.1774616218172014e-05\n",
      "For Epoch42 SuperVised_Loss:2.2289535999298096,       VAT_loss = 3.979014218202792e-05,   Total_Loss:2.2289934158325195\n",
      "For Epoch42 VAT_LOSS_UNLABELED:3.2024370739236474e-05\n",
      "For Epoch43 SuperVised_Loss:2.1859841346740723,       VAT_loss = 3.1144874810706824e-05,   Total_Loss:2.1860153675079346\n",
      "For Epoch43 VAT_LOSS_UNLABELED:3.583652505767532e-05\n",
      "For Epoch44 SuperVised_Loss:1.9407840967178345,       VAT_loss = 3.463983375695534e-05,   Total_Loss:1.9408187866210938\n",
      "For Epoch44 VAT_LOSS_UNLABELED:3.577450115699321e-05\n",
      "For Epoch45 SuperVised_Loss:1.9114177227020264,       VAT_loss = 4.078670099261217e-05,   Total_Loss:1.9114584922790527\n",
      "For Epoch45 VAT_LOSS_UNLABELED:3.454862962826155e-05\n",
      "For Epoch46 SuperVised_Loss:2.2109670639038086,       VAT_loss = 3.888807987095788e-05,   Total_Loss:2.211005926132202\n",
      "For Epoch46 VAT_LOSS_UNLABELED:3.4433942346367985e-05\n",
      "For Epoch47 SuperVised_Loss:2.1838314533233643,       VAT_loss = 4.092338349437341e-05,   Total_Loss:2.1838724613189697\n",
      "For Epoch47 VAT_LOSS_UNLABELED:3.829419438261539e-05\n",
      "For Epoch48 SuperVised_Loss:1.9536030292510986,       VAT_loss = 4.3557451135711744e-05,   Total_Loss:1.9536465406417847\n",
      "For Epoch48 VAT_LOSS_UNLABELED:4.414019713294692e-05\n",
      "For Epoch49 SuperVised_Loss:2.182863712310791,       VAT_loss = 4.270161662134342e-05,   Total_Loss:2.18290638923645\n",
      "For Epoch49 VAT_LOSS_UNLABELED:3.541057594702579e-05\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.01)\n",
    "optimizer2 = optim.SGD(model1.parameters(), lr = 0.001)\n",
    "num_epochs = 50\n",
    "supervised_loss = 0\n",
    "VAT_loss = 0\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    \n",
    "    # Train on labeled data\n",
    "    for images, labels in labeledLoader:\n",
    "        optimizer1.zero_grad()\n",
    "        outputs = model1(images)\n",
    "        supervised_loss = F.cross_entropy(outputs, labels)\n",
    "        VAT_loss_labeled = virtual_adversarial_loss(model1, images, epsilon=0.02)\n",
    "        total_loss = supervised_loss + VAT_loss_labeled\n",
    "        total_loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "    print(f\"For Epoch{epoch} SuperVised_Loss:{supervised_loss},       VAT_loss = {VAT_loss_labeled},   Total_Loss:{total_loss}\")\n",
    "    \n",
    "    # Train on unlabeled data\n",
    "    for images, labels in unlabeledLoader:\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        vat_loss_unlabeled = virtual_adversarial_loss(model1, images, epsilon=0.02)\n",
    "        vat_loss_unlabeled.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "    \n",
    "    print(f\"For Epoch{epoch} VAT_LOSS_UNLABELED:{vat_loss_unlabeled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.0%\n",
      "Testing Accuracy: 16.01010101010101%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(loader,model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  \n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "train_accuracy = calculate_accuracy(labeledLoader, model1)\n",
    "test_accuracy = calculate_accuracy(unlabeledLoader, model1)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy}%')\n",
    "print(f'Testing Accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAT for Two Moons Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_samples = np.load('./selected_samples.npy')\n",
    "\n",
    "remaining_samples = np.load('./remaining_dataset.npy')\n",
    "\n",
    "# Converting the selected samples and remaining samples into PyTorch tensors\n",
    "selected_samples_tensor = torch.tensor(selected_samples, dtype=torch.float32)\n",
    "remaining_samples_tensor = torch.tensor(remaining_samples, dtype=torch.float32)\n",
    "\n",
    "# Extracting features and labels for both datasets\n",
    "features_selected = selected_samples_tensor[:, :2]\n",
    "labels_selected = selected_samples_tensor[:, 2].long()  # converting labels to long for classification\n",
    "\n",
    "features_remaining = remaining_samples_tensor[:, :2]\n",
    "labels_remaining = remaining_samples_tensor[:, 2].long()\n",
    "\n",
    "# Creating TensorDatasets\n",
    "selected_dataset = TensorDataset(features_selected, labels_selected)\n",
    "remaining_dataset = TensorDataset(features_remaining, labels_remaining)\n",
    "\n",
    "# Creating DataLoaders\n",
    "selected_loader = DataLoader(selected_dataset, batch_size=1)  # small batch size for the small dataset\n",
    "remaining_loader = DataLoader(remaining_dataset, batch_size=10)  # larger batch size for the larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoMoonsNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(TwoMoonsNet,self).__init__()\n",
    "\n",
    "        self.fullyConnectedLayer = nn.Sequential(\n",
    "            nn.Linear(2, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.fullyConnectedLayer(input)\n",
    "        activatedOutput = F.log_softmax(output, dim = 1)\n",
    "\n",
    "        return activatedOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = TwoMoonsNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Epoch0 SuperVised_Loss:0.13327543437480927,       VAT_loss = 1.1388328857719898e-07,   Total_Loss:0.13327555358409882\n",
      "For Epoch0 VAT_LOSS_UNLABELED:9.214194142259657e-05\n",
      "For Epoch1 SuperVised_Loss:0.1309199035167694,       VAT_loss = 3.628828562796116e-05,   Total_Loss:0.13095618784427643\n",
      "For Epoch1 VAT_LOSS_UNLABELED:1.4502278645522892e-05\n",
      "For Epoch2 SuperVised_Loss:0.12861710786819458,       VAT_loss = 5.523033905774355e-07,   Total_Loss:0.12861765921115875\n",
      "For Epoch2 VAT_LOSS_UNLABELED:0.0004363400803413242\n",
      "For Epoch3 SuperVised_Loss:0.12636582553386688,       VAT_loss = 2.238526940345764e-05,   Total_Loss:0.12638820707798004\n",
      "For Epoch3 VAT_LOSS_UNLABELED:0.0001563768310006708\n",
      "For Epoch4 SuperVised_Loss:0.12416380643844604,       VAT_loss = 2.7777859941124916e-06,   Total_Loss:0.1241665855050087\n",
      "For Epoch4 VAT_LOSS_UNLABELED:6.358710379572585e-06\n",
      "For Epoch5 SuperVised_Loss:0.12201178818941116,       VAT_loss = 1.6749254427850246e-08,   Total_Loss:0.12201180309057236\n",
      "For Epoch5 VAT_LOSS_UNLABELED:0.0001541944220662117\n",
      "For Epoch6 SuperVised_Loss:0.11990789324045181,       VAT_loss = 7.097888737916946e-05,   Total_Loss:0.1199788749217987\n",
      "For Epoch6 VAT_LOSS_UNLABELED:9.117429726757109e-05\n",
      "For Epoch7 SuperVised_Loss:0.11784926056861877,       VAT_loss = 1.0020448826253414e-07,   Total_Loss:0.11784935742616653\n",
      "For Epoch7 VAT_LOSS_UNLABELED:7.95850864960812e-05\n",
      "For Epoch8 SuperVised_Loss:0.11583734303712845,       VAT_loss = 0.00023373030126094818,   Total_Loss:0.11607107520103455\n",
      "For Epoch8 VAT_LOSS_UNLABELED:1.7336082237306982e-05\n",
      "For Epoch9 SuperVised_Loss:0.11386871337890625,       VAT_loss = 5.2249059081077576e-05,   Total_Loss:0.11392096430063248\n",
      "For Epoch9 VAT_LOSS_UNLABELED:7.76984597905539e-05\n",
      "For Epoch10 SuperVised_Loss:0.11194213479757309,       VAT_loss = 9.476765990257263e-05,   Total_Loss:0.11203689873218536\n",
      "For Epoch10 VAT_LOSS_UNLABELED:7.31309992261231e-05\n",
      "For Epoch11 SuperVised_Loss:0.1100575402379036,       VAT_loss = 5.600159056484699e-06,   Total_Loss:0.11006314307451248\n",
      "For Epoch11 VAT_LOSS_UNLABELED:3.80830024369061e-05\n",
      "For Epoch12 SuperVised_Loss:0.10821743309497833,       VAT_loss = 2.652662806212902e-05,   Total_Loss:0.10824395716190338\n",
      "For Epoch12 VAT_LOSS_UNLABELED:9.235585457645357e-05\n",
      "For Epoch13 SuperVised_Loss:0.10641304403543472,       VAT_loss = 3.6045676097273827e-06,   Total_Loss:0.10641665011644363\n",
      "For Epoch13 VAT_LOSS_UNLABELED:8.096669625956565e-05\n",
      "For Epoch14 SuperVised_Loss:0.10464566200971603,       VAT_loss = 1.8605263903737068e-05,   Total_Loss:0.10466426610946655\n",
      "For Epoch14 VAT_LOSS_UNLABELED:0.00013572150783147663\n",
      "For Epoch15 SuperVised_Loss:0.10291655361652374,       VAT_loss = 1.33920693770051e-05,   Total_Loss:0.10292994230985641\n",
      "For Epoch15 VAT_LOSS_UNLABELED:0.0002205117925768718\n",
      "For Epoch16 SuperVised_Loss:0.10122355818748474,       VAT_loss = 1.028645783662796e-06,   Total_Loss:0.10122458636760712\n",
      "For Epoch16 VAT_LOSS_UNLABELED:3.8470687286462635e-05\n",
      "For Epoch17 SuperVised_Loss:0.09956686943769455,       VAT_loss = 7.399066817015409e-07,   Total_Loss:0.09956760704517365\n",
      "For Epoch17 VAT_LOSS_UNLABELED:0.00013265793677419424\n",
      "For Epoch18 SuperVised_Loss:0.09794504195451736,       VAT_loss = 2.537504769861698e-05,   Total_Loss:0.09797041863203049\n",
      "For Epoch18 VAT_LOSS_UNLABELED:0.0001326617639278993\n",
      "For Epoch19 SuperVised_Loss:0.09635728597640991,       VAT_loss = 6.659305654466152e-06,   Total_Loss:0.09636394679546356\n",
      "For Epoch19 VAT_LOSS_UNLABELED:0.0001621402334421873\n",
      "For Epoch20 SuperVised_Loss:0.09480082988739014,       VAT_loss = 1.7085927538573742e-05,   Total_Loss:0.09481791406869888\n",
      "For Epoch20 VAT_LOSS_UNLABELED:0.000355540425516665\n",
      "For Epoch21 SuperVised_Loss:0.0932764858007431,       VAT_loss = 1.3411627151072025e-06,   Total_Loss:0.09327782690525055\n",
      "For Epoch21 VAT_LOSS_UNLABELED:0.00018791589536704123\n",
      "For Epoch22 SuperVised_Loss:0.09178373962640762,       VAT_loss = 1.276121474802494e-05,   Total_Loss:0.09179650247097015\n",
      "For Epoch22 VAT_LOSS_UNLABELED:3.554290015017614e-05\n",
      "For Epoch23 SuperVised_Loss:0.09032122045755386,       VAT_loss = 1.9579660147428513e-05,   Total_Loss:0.09034080058336258\n",
      "For Epoch23 VAT_LOSS_UNLABELED:9.731127647683024e-06\n",
      "For Epoch24 SuperVised_Loss:0.08888863027095795,       VAT_loss = 5.669589154422283e-05,   Total_Loss:0.08894532918930054\n",
      "For Epoch24 VAT_LOSS_UNLABELED:7.625784928677604e-05\n",
      "For Epoch25 SuperVised_Loss:0.08748511224985123,       VAT_loss = 3.292271867394447e-05,   Total_Loss:0.08751803636550903\n",
      "For Epoch25 VAT_LOSS_UNLABELED:3.23842978104949e-05\n",
      "For Epoch26 SuperVised_Loss:0.08610958606004715,       VAT_loss = 2.8329086489975452e-06,   Total_Loss:0.08611241728067398\n",
      "For Epoch26 VAT_LOSS_UNLABELED:0.0011876998469233513\n",
      "For Epoch27 SuperVised_Loss:0.08476217836141586,       VAT_loss = 2.25964467972517e-05,   Total_Loss:0.08478477597236633\n",
      "For Epoch27 VAT_LOSS_UNLABELED:1.1219606676604599e-05\n",
      "For Epoch28 SuperVised_Loss:0.08344157785177231,       VAT_loss = 3.462005406618118e-05,   Total_Loss:0.08347620069980621\n",
      "For Epoch28 VAT_LOSS_UNLABELED:7.87572207627818e-06\n",
      "For Epoch29 SuperVised_Loss:0.08214646577835083,       VAT_loss = 6.235088221728802e-06,   Total_Loss:0.08215270191431046\n",
      "For Epoch29 VAT_LOSS_UNLABELED:0.00010648046736605465\n",
      "For Epoch30 SuperVised_Loss:0.08087682723999023,       VAT_loss = 3.019440919160843e-05,   Total_Loss:0.08090702444314957\n",
      "For Epoch30 VAT_LOSS_UNLABELED:0.00018047045159619302\n",
      "For Epoch31 SuperVised_Loss:0.07963276654481888,       VAT_loss = 1.0234187357127666e-05,   Total_Loss:0.07964300364255905\n",
      "For Epoch31 VAT_LOSS_UNLABELED:0.00018037298286799341\n",
      "For Epoch32 SuperVised_Loss:0.07841294258832932,       VAT_loss = 6.7828805185854435e-06,   Total_Loss:0.07841972261667252\n",
      "For Epoch32 VAT_LOSS_UNLABELED:0.0004241249116603285\n",
      "For Epoch33 SuperVised_Loss:0.07721856236457825,       VAT_loss = 1.4921301044523716e-05,   Total_Loss:0.07723348587751389\n",
      "For Epoch33 VAT_LOSS_UNLABELED:4.8340869398089126e-05\n",
      "For Epoch34 SuperVised_Loss:0.07604794204235077,       VAT_loss = 0.0001022114884108305,   Total_Loss:0.07615015655755997\n",
      "For Epoch34 VAT_LOSS_UNLABELED:2.1247515178401954e-05\n",
      "For Epoch35 SuperVised_Loss:0.07489751279354095,       VAT_loss = 2.7025234885513783e-06,   Total_Loss:0.07490021735429764\n",
      "For Epoch35 VAT_LOSS_UNLABELED:5.254369170870632e-05\n",
      "For Epoch36 SuperVised_Loss:0.07377167791128159,       VAT_loss = 1.7443089745938778e-06,   Total_Loss:0.07377342134714127\n",
      "For Epoch36 VAT_LOSS_UNLABELED:5.730784323532134e-05\n",
      "For Epoch37 SuperVised_Loss:0.07266685366630554,       VAT_loss = 1.5250174328684807e-05,   Total_Loss:0.07268210500478745\n",
      "For Epoch37 VAT_LOSS_UNLABELED:0.00014019587251823395\n",
      "For Epoch38 SuperVised_Loss:0.07158166915178299,       VAT_loss = 8.252006955444813e-05,   Total_Loss:0.07166419178247452\n",
      "For Epoch38 VAT_LOSS_UNLABELED:0.0006501969182863832\n",
      "For Epoch39 SuperVised_Loss:0.07051718980073929,       VAT_loss = 2.0582112483680248e-05,   Total_Loss:0.07053776830434799\n",
      "For Epoch39 VAT_LOSS_UNLABELED:0.00010060322529170662\n",
      "For Epoch40 SuperVised_Loss:0.06947360187768936,       VAT_loss = 2.6930589228868484e-05,   Total_Loss:0.06950053572654724\n",
      "For Epoch40 VAT_LOSS_UNLABELED:4.781142342835665e-05\n",
      "For Epoch41 SuperVised_Loss:0.06845084577798843,       VAT_loss = 3.474706318229437e-06,   Total_Loss:0.0684543177485466\n",
      "For Epoch41 VAT_LOSS_UNLABELED:0.0002155232650693506\n",
      "For Epoch42 SuperVised_Loss:0.06744666397571564,       VAT_loss = 2.4073640815913677e-05,   Total_Loss:0.0674707368016243\n",
      "For Epoch42 VAT_LOSS_UNLABELED:6.76032286719419e-05\n",
      "For Epoch43 SuperVised_Loss:0.06646176427602768,       VAT_loss = 9.155110456049442e-05,   Total_Loss:0.06655331701040268\n",
      "For Epoch43 VAT_LOSS_UNLABELED:6.908761861268431e-05\n",
      "For Epoch44 SuperVised_Loss:0.06549398601055145,       VAT_loss = 6.968271918594837e-06,   Total_Loss:0.06550095230340958\n",
      "For Epoch44 VAT_LOSS_UNLABELED:1.0671808013285045e-05\n",
      "For Epoch45 SuperVised_Loss:0.06454461067914963,       VAT_loss = 4.4572516344487667e-07,   Total_Loss:0.06454505771398544\n",
      "For Epoch45 VAT_LOSS_UNLABELED:0.0002962463768199086\n",
      "For Epoch46 SuperVised_Loss:0.06361289322376251,       VAT_loss = 1.1895433999598026e-05,   Total_Loss:0.0636247918009758\n",
      "For Epoch46 VAT_LOSS_UNLABELED:5.544596933759749e-05\n",
      "For Epoch47 SuperVised_Loss:0.06269823014736176,       VAT_loss = 9.511131793260574e-06,   Total_Loss:0.06270774453878403\n",
      "For Epoch47 VAT_LOSS_UNLABELED:3.313241177238524e-05\n",
      "For Epoch48 SuperVised_Loss:0.06180053949356079,       VAT_loss = 5.3481897339224815e-05,   Total_Loss:0.06185401976108551\n",
      "For Epoch48 VAT_LOSS_UNLABELED:1.6599424270680174e-05\n",
      "For Epoch49 SuperVised_Loss:0.06091943383216858,       VAT_loss = 2.0017614588141441e-07,   Total_Loss:0.060919634997844696\n",
      "For Epoch49 VAT_LOSS_UNLABELED:9.507876529823989e-05\n",
      "For Epoch50 SuperVised_Loss:0.06005449965596199,       VAT_loss = 6.429082714021206e-05,   Total_Loss:0.060118790715932846\n",
      "For Epoch50 VAT_LOSS_UNLABELED:6.31924340268597e-05\n",
      "For Epoch51 SuperVised_Loss:0.059205446392297745,       VAT_loss = 1.3354816474020481e-05,   Total_Loss:0.05921880155801773\n",
      "For Epoch51 VAT_LOSS_UNLABELED:0.0003545737126842141\n",
      "For Epoch52 SuperVised_Loss:0.05837265029549599,       VAT_loss = 1.8257996998727322e-06,   Total_Loss:0.05837447568774223\n",
      "For Epoch52 VAT_LOSS_UNLABELED:0.00012390059418976307\n",
      "For Epoch53 SuperVised_Loss:0.057554468512535095,       VAT_loss = 3.4239492379128933e-06,   Total_Loss:0.05755789205431938\n",
      "For Epoch53 VAT_LOSS_UNLABELED:0.00047321830061264336\n",
      "For Epoch54 SuperVised_Loss:0.05675115808844566,       VAT_loss = 2.0202132873237133e-06,   Total_Loss:0.05675317719578743\n",
      "For Epoch54 VAT_LOSS_UNLABELED:9.75737493718043e-05\n",
      "For Epoch55 SuperVised_Loss:0.055962421000003815,       VAT_loss = 1.276389230042696e-05,   Total_Loss:0.055975183844566345\n",
      "For Epoch55 VAT_LOSS_UNLABELED:0.0003076055727433413\n",
      "For Epoch56 SuperVised_Loss:0.0551888532936573,       VAT_loss = 3.562367055565119e-06,   Total_Loss:0.05519241467118263\n",
      "For Epoch56 VAT_LOSS_UNLABELED:0.00012343350681476295\n",
      "For Epoch57 SuperVised_Loss:0.05442812293767929,       VAT_loss = 1.3704702723771334e-06,   Total_Loss:0.054429493844509125\n",
      "For Epoch57 VAT_LOSS_UNLABELED:0.00032113189809024334\n",
      "For Epoch58 SuperVised_Loss:0.05368206277489662,       VAT_loss = 2.9892544262111187e-05,   Total_Loss:0.05371195450425148\n",
      "For Epoch58 VAT_LOSS_UNLABELED:7.332742097787559e-05\n",
      "For Epoch59 SuperVised_Loss:0.05295014753937721,       VAT_loss = 7.32991611585021e-06,   Total_Loss:0.052957478910684586\n",
      "For Epoch59 VAT_LOSS_UNLABELED:1.2014922504022252e-05\n",
      "For Epoch60 SuperVised_Loss:0.05222912132740021,       VAT_loss = 8.129514753818512e-05,   Total_Loss:0.05231041461229324\n",
      "For Epoch60 VAT_LOSS_UNLABELED:2.691400732146576e-05\n",
      "For Epoch61 SuperVised_Loss:0.051520708948373795,       VAT_loss = 2.9613031074404716e-05,   Total_Loss:0.05155032128095627\n",
      "For Epoch61 VAT_LOSS_UNLABELED:1.633092324482277e-05\n",
      "For Epoch62 SuperVised_Loss:0.05082618445158005,       VAT_loss = 1.7770915292203426e-05,   Total_Loss:0.05084395408630371\n",
      "For Epoch62 VAT_LOSS_UNLABELED:0.0001684788439888507\n",
      "For Epoch63 SuperVised_Loss:0.050143081694841385,       VAT_loss = 0.00010257307440042496,   Total_Loss:0.050245653837919235\n",
      "For Epoch63 VAT_LOSS_UNLABELED:0.00017276992730330676\n",
      "For Epoch64 SuperVised_Loss:0.04947176203131676,       VAT_loss = 4.492540028877556e-08,   Total_Loss:0.04947180673480034\n",
      "For Epoch64 VAT_LOSS_UNLABELED:6.386943277902901e-05\n",
      "For Epoch65 SuperVised_Loss:0.048812031745910645,       VAT_loss = 4.534813342615962e-07,   Total_Loss:0.04881248623132706\n",
      "For Epoch65 VAT_LOSS_UNLABELED:0.0002905898436438292\n",
      "For Epoch66 SuperVised_Loss:0.04816481098532677,       VAT_loss = 1.0437506716698408e-06,   Total_Loss:0.048165854066610336\n",
      "For Epoch66 VAT_LOSS_UNLABELED:8.733575668884441e-05\n",
      "For Epoch67 SuperVised_Loss:0.04752854257822037,       VAT_loss = 7.945054676383734e-07,   Total_Loss:0.04752933606505394\n",
      "For Epoch67 VAT_LOSS_UNLABELED:7.599299715366215e-05\n",
      "For Epoch68 SuperVised_Loss:0.04690392687916756,       VAT_loss = 1.1830939911305904e-05,   Total_Loss:0.04691575840115547\n",
      "For Epoch68 VAT_LOSS_UNLABELED:8.657084254082292e-05\n",
      "For Epoch69 SuperVised_Loss:0.04628916084766388,       VAT_loss = 0.00013934890739619732,   Total_Loss:0.046428509056568146\n",
      "For Epoch69 VAT_LOSS_UNLABELED:0.00022710248595103621\n",
      "For Epoch70 SuperVised_Loss:0.045685406774282455,       VAT_loss = 6.88240397721529e-05,   Total_Loss:0.04575423151254654\n",
      "For Epoch70 VAT_LOSS_UNLABELED:0.00020194839453324676\n",
      "For Epoch71 SuperVised_Loss:0.045091431587934494,       VAT_loss = 4.526262637227774e-05,   Total_Loss:0.045136693865060806\n",
      "For Epoch71 VAT_LOSS_UNLABELED:0.00040479793096892536\n",
      "For Epoch72 SuperVised_Loss:0.04450930282473564,       VAT_loss = 7.588649168610573e-06,   Total_Loss:0.04451689124107361\n",
      "For Epoch72 VAT_LOSS_UNLABELED:0.0006606239476241171\n",
      "For Epoch73 SuperVised_Loss:0.043935734778642654,       VAT_loss = 5.008478183299303e-07,   Total_Loss:0.04393623396754265\n",
      "For Epoch73 VAT_LOSS_UNLABELED:3.736013240995817e-05\n",
      "For Epoch74 SuperVised_Loss:0.043371766805648804,       VAT_loss = 3.6051031202077866e-05,   Total_Loss:0.04340781643986702\n",
      "For Epoch74 VAT_LOSS_UNLABELED:0.00011855336924782023\n",
      "For Epoch75 SuperVised_Loss:0.0428181029856205,       VAT_loss = 5.964713636785746e-06,   Total_Loss:0.042824067175388336\n",
      "For Epoch75 VAT_LOSS_UNLABELED:9.547648369334638e-05\n",
      "For Epoch76 SuperVised_Loss:0.04227430000901222,       VAT_loss = 3.3379183150827885e-06,   Total_Loss:0.042277637869119644\n",
      "For Epoch76 VAT_LOSS_UNLABELED:0.00043491399264894426\n",
      "For Epoch77 SuperVised_Loss:0.04173866659402847,       VAT_loss = 1.22488709166646e-05,   Total_Loss:0.041750915348529816\n",
      "For Epoch77 VAT_LOSS_UNLABELED:0.0002743582590483129\n",
      "For Epoch78 SuperVised_Loss:0.04121280834078789,       VAT_loss = 6.3715735450387e-05,   Total_Loss:0.04127652570605278\n",
      "For Epoch78 VAT_LOSS_UNLABELED:0.0014340850757434964\n",
      "For Epoch79 SuperVised_Loss:0.040695834904909134,       VAT_loss = 0.00013305828906595707,   Total_Loss:0.0408288948237896\n",
      "For Epoch79 VAT_LOSS_UNLABELED:0.0009511952521279454\n",
      "For Epoch80 SuperVised_Loss:0.04018683731555939,       VAT_loss = 9.042967576533556e-06,   Total_Loss:0.040195878595113754\n",
      "For Epoch80 VAT_LOSS_UNLABELED:4.3594140151981264e-05\n",
      "For Epoch81 SuperVised_Loss:0.03968663141131401,       VAT_loss = 2.3554195649921894e-05,   Total_Loss:0.039710186421871185\n",
      "For Epoch81 VAT_LOSS_UNLABELED:7.298520358745009e-05\n",
      "For Epoch82 SuperVised_Loss:0.03919431194663048,       VAT_loss = 9.209499694406986e-06,   Total_Loss:0.039203520864248276\n",
      "For Epoch82 VAT_LOSS_UNLABELED:0.0006214806926436722\n",
      "For Epoch83 SuperVised_Loss:0.038710467517375946,       VAT_loss = 2.680375473573804e-06,   Total_Loss:0.03871314972639084\n",
      "For Epoch83 VAT_LOSS_UNLABELED:0.000866463640704751\n",
      "For Epoch84 SuperVised_Loss:0.038235798478126526,       VAT_loss = 1.0814634151756763e-05,   Total_Loss:0.03824661299586296\n",
      "For Epoch84 VAT_LOSS_UNLABELED:1.88125795830274e-06\n",
      "For Epoch85 SuperVised_Loss:0.037768132984638214,       VAT_loss = 4.253524821251631e-07,   Total_Loss:0.03776855766773224\n",
      "For Epoch85 VAT_LOSS_UNLABELED:0.00046634190948680043\n",
      "For Epoch86 SuperVised_Loss:0.03730829060077667,       VAT_loss = 7.712573278695345e-06,   Total_Loss:0.03731600195169449\n",
      "For Epoch86 VAT_LOSS_UNLABELED:0.00015695375623181462\n",
      "For Epoch87 SuperVised_Loss:0.03685513138771057,       VAT_loss = 2.981908619403839e-05,   Total_Loss:0.03688494861125946\n",
      "For Epoch87 VAT_LOSS_UNLABELED:0.000868317496497184\n",
      "For Epoch88 SuperVised_Loss:0.03640946373343468,       VAT_loss = 3.167672548443079e-05,   Total_Loss:0.0364411398768425\n",
      "For Epoch88 VAT_LOSS_UNLABELED:4.5130771468393505e-05\n",
      "For Epoch89 SuperVised_Loss:0.035971879959106445,       VAT_loss = 3.800378181040287e-06,   Total_Loss:0.035975679755210876\n",
      "For Epoch89 VAT_LOSS_UNLABELED:0.00020094330830033869\n",
      "For Epoch90 SuperVised_Loss:0.035540662705898285,       VAT_loss = 1.2624484952539206e-05,   Total_Loss:0.03555328771471977\n",
      "For Epoch90 VAT_LOSS_UNLABELED:4.784660995937884e-05\n",
      "For Epoch91 SuperVised_Loss:0.03511708602309227,       VAT_loss = 1.9351718947291374e-06,   Total_Loss:0.03511901944875717\n",
      "For Epoch91 VAT_LOSS_UNLABELED:0.0007271856302395463\n",
      "For Epoch92 SuperVised_Loss:0.03470023721456528,       VAT_loss = 4.0436978451907635e-05,   Total_Loss:0.03474067524075508\n",
      "For Epoch92 VAT_LOSS_UNLABELED:0.0002783887321129441\n",
      "For Epoch93 SuperVised_Loss:0.03429001197218895,       VAT_loss = 9.370705811306834e-08,   Total_Loss:0.03429010510444641\n",
      "For Epoch93 VAT_LOSS_UNLABELED:0.00012967702059540898\n",
      "For Epoch94 SuperVised_Loss:0.03388676047325134,       VAT_loss = 1.945474650710821e-06,   Total_Loss:0.03388870507478714\n",
      "For Epoch94 VAT_LOSS_UNLABELED:2.58629625022877e-05\n",
      "For Epoch95 SuperVised_Loss:0.033489227294921875,       VAT_loss = 8.292437996715307e-06,   Total_Loss:0.03349751979112625\n",
      "For Epoch95 VAT_LOSS_UNLABELED:0.00012674422760028392\n",
      "For Epoch96 SuperVised_Loss:0.033098459243774414,       VAT_loss = 1.91314029507339e-07,   Total_Loss:0.033098649233579636\n",
      "For Epoch96 VAT_LOSS_UNLABELED:0.0003509301459416747\n",
      "For Epoch97 SuperVised_Loss:0.03271341696381569,       VAT_loss = 3.729923628270626e-05,   Total_Loss:0.03275071457028389\n",
      "For Epoch97 VAT_LOSS_UNLABELED:4.4034542952431366e-05\n",
      "For Epoch98 SuperVised_Loss:0.03233376890420914,       VAT_loss = 1.032138243317604e-05,   Total_Loss:0.032344091683626175\n",
      "For Epoch98 VAT_LOSS_UNLABELED:0.00021319175721146166\n",
      "For Epoch99 SuperVised_Loss:0.031960904598236084,       VAT_loss = 4.937028279528022e-07,   Total_Loss:0.03196140006184578\n",
      "For Epoch99 VAT_LOSS_UNLABELED:1.4747067325515673e-05\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer1 = optim.SGD(model2.parameters(), lr=0.01)\n",
    "optimizer2 = optim.SGD(model2.parameters(), lr = 0.001)\n",
    "num_epochs = 100\n",
    "supervised_loss = 0\n",
    "VAT_loss = 0\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    \n",
    "    # Train on labeled data\n",
    "    for images, labels in selected_loader:\n",
    "        optimizer1.zero_grad()\n",
    "        outputs = model2(images)\n",
    "        supervised_loss = F.cross_entropy(outputs, labels)\n",
    "        VAT_loss_labeled = virtual_adversarial_loss(model2, images, epsilon=0.02)\n",
    "        total_loss = supervised_loss + VAT_loss_labeled\n",
    "        total_loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "    print(f\"For Epoch{epoch} SuperVised_Loss:{supervised_loss},       VAT_loss = {VAT_loss_labeled},   Total_Loss:{total_loss}\")\n",
    "    \n",
    "    # Train on unlabeled data\n",
    "    for images, labels in remaining_loader:\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        vat_loss_unlabeled = virtual_adversarial_loss(model2, images, epsilon=0.02)\n",
    "        vat_loss_unlabeled.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "    \n",
    "    print(f\"For Epoch{epoch} VAT_LOSS_UNLABELED:{vat_loss_unlabeled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.0%\n",
      "Testing Accuracy: 72.34042553191489%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(selected_loader, model2)\n",
    "test_accuracy = calculate_accuracy(remaining_loader, model2)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy}%')\n",
    "print(f'Testing Accuracy: {test_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
